# NFX-Identity Configuration Example
# Copy this file to inputs/*/config/dev.toml or inputs/*/config/prod.toml and modify according to your environment

[server]
    name = "Service Name"
    host = "0.0.0.0"
    http_port = 8080
    grpc_port = 10012

[postgresql]
    host = "localhost"
    port = 5432
    user = "postgres"
    password = "your-password-here"
    dbname = "nfxid_dev"
    sslmode = "disable"
    timezone = "UTC"
    logger_level = "warn"
    auto_migrate = false

    [postgresql.connection]
        timeout = "5s"
        max_retries = 5
        retry_interval = "2s"
        max_idle_connections = 10
        max_open_connections = 100
        conn_max_idle_time = "15m"
        conn_max_lifetime = "1h"

[mongodb]
    host = "localhost"
    port = 27017
    user = "admin"
    password = "your-password-here"
    auth_source = "admin"
    database = "nfxid_dev"
    min_pool_size = 1
    max_pool_size = 10
    connect_timeout = "5s"
    ping_timeout = "2s"
    [mongodb.retry]
        max_retries = 5
        initial_backoff = "1s"

[cache]
    host = "localhost"
    port = 6379
    password = "your-password-here"

    [cache.connection]
        dial_timeout = "3s"
        write_timeout = "3s"
        read_timeout = "3s"
        max_retries = 5
        retry_interval = "2s"

    [cache.tls]
        enabled = false
        server_name = ""

[logger]
    level = "debug"
    format = "console"
    output = "stdout"
    file_path = "logs/service.log"
    max_size_mb = 100
    max_backups = 10
    max_age_day = 30
    compress = false

[token]
    secret_key = "your-secret-key-here-change-in-production"
    issuer = "nfxid"
    access_token_ttl = "24h"
    refresh_token_ttl = "168h"
    algorithm = "HS256"

[storage]
    base_path = "./data"

[kafka]
    brokers = ["localhost:9092"]
    client_id = "nfxid-service"

    [kafka.network]
        max_open_requests = 1

    [kafka.producer]
        acks = "all"
        compression = "snappy"
        retries = 3
        batch_bytes = 1048576
        linger_ms = 5
        idempotent = true

    [kafka.consumer]
        group_id = "service-group"
        initial_offset = "latest"
        session_timeout_ms = 10000
        heartbeat_interval_ms = 3000
        fetch_min_bytes = 1
        fetch_max_bytes = 5242880
        return_errors = true

    [kafka.producer_topics]
        # Service-specific topics - modify according to service
        event = "event"
        event_poison = "event_poison"

    [kafka.consumer_topics]
        # Service-specific topics - modify according to service
        event = "event"
        event_poison = "event_poison"

    [kafka.security]
        enabled = false
        mechanism = "PLAIN"
        username = ""
        password = ""
        tls_insecure_skip_verify = false

[rabbitmq]
    uri = "amqp://guest:guest@localhost:5672/"
    client_id = "nfxid-service"

    [rabbitmq.producer]
        mandatory = false
        immediate = false
        content_type = "application/json"
        delivery_mode = 2  # 2=持久化, 1=非持久化
        confirm_delivery = true  # 发布确认（RabbitMQ 特有）
        channel_pool_size = 10  # 通道池大小（性能优化）
        transactional = false  # 事务模式
        default_priority = 0  # 默认消息优先级（0-255），0 表示不设置优先级（RabbitMQ 特有）

    [rabbitmq.consumer]
        queue_name = ""  # 如果为空则根据 topic 生成
        consumer_tag = "nfxid-consumer"
        auto_ack = false
        exclusive = false
        no_local = false
        no_wait = false
        no_requeue_on_nack = false  # Nack 时不重新入队
        prefetch_count = 10  # 预取数量
        prefetch_size = 0  # 预取大小（字节），0 表示不限制
        qos_global = false  # QOS 是否全局应用

    [rabbitmq.connection]
        [rabbitmq.connection.tls]
            enabled = false
            insecure_skip_verify = false
            cert_file = ""
            key_file = ""
            ca_file = ""
            server_name = ""

        [rabbitmq.connection.reconnect]
            enabled = true
            initial_interval = "1s"
            randomization_factor = 0.5
            multiplier = 1.5
            max_interval = "30s"

        [rabbitmq.connection.amqp]
            vhost = "/"  # 虚拟主机
            heartbeat = 10  # 心跳间隔（秒），0 表示禁用
            locale = "en_US"
            channel_max = 0  # 最大通道数，0 表示无限制
            frame_size = 0  # 最大帧大小，0 表示使用默认值

    [rabbitmq.exchange]
        name = ""  # 如果为空则根据 topic 生成
        type = "topic"  # direct, topic, fanout, headers
        durable = true
        auto_delete = false
        internal = false
        no_wait = false

    [rabbitmq.queue]
        durable = true
        auto_delete = false
        exclusive = false
        no_wait = false

        # 优先级队列（Priority Queue）
        max_priority = 0  # 队列最大优先级（0-255），0 表示不启用优先级队列

        # 延迟队列（Delayed Queue / Message TTL）
        message_ttl = 0  # 消息 TTL（毫秒），0 表示不设置 TTL

        # 队列限制
        max_length = 0  # 队列最大消息数，0 表示不限制
        max_length_bytes = 0  # 队列最大字节数，0 表示不限制

        # 死信队列（Dead Letter Queue）
        dead_letter_exchange = ""  # 死信交换机名称
        dead_letter_routing_key = ""  # 死信路由键

    [rabbitmq.queue_bind]
        routing_key = ""  # 如果为空则使用 topic 名称
        no_wait = false

    [rabbitmq.producer_exchanges]
        # 映射消息键（MessageKey）到 Exchange 和 RoutingKey
        # 格式: message_key = {exchange = "exchange_name", routing_key = "routing.key"}
        # 如果 exchange 为空，使用 exchange.name 配置或根据消息键自动生成
        # 如果 routing_key 为空，使用消息键作为 routing_key
        event = {exchange = "", routing_key = "event"}
        event_poison = {exchange = "", routing_key = "event.poison"}

    [rabbitmq.consumer_queues]
        # 映射消息键（MessageKey）到 Queue 和 BindingKey
        # 格式: message_key = {queue = "queue_name", binding_key = "binding.key"}
        # 如果 queue 为空，使用 consumer.queue_name 配置或根据消息键自动生成
        # 如果 binding_key 为空，使用消息键作为 binding_key
        event = {queue = "", binding_key = "event"}
        event_poison = {queue = "", binding_key = "event.poison"}

[email]
    smtp_host = "smtp.gmail.com"
    smtp_port = 587
    smtp_user = "your-email@gmail.com"
    smtp_password = "your-app-password-here"
    smtp_from = "your-email@gmail.com"

[grpc_client]
    # Service-specific gRPC client addresses - modify according to service
    # auth_addr = "localhost:10012"
    # image_addr = "localhost:10013"
